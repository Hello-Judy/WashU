{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb9475d3-ee8d-4e43-9b1f-e02af458a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember type conda activate test_env_gpu\n",
    "#Library Part\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cupy as cp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c1ff0-fa0f-4ba2-97e9-6bca815a7ca5",
   "metadata": {},
   "source": [
    "####  Access the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2389eb-8fe0-40d2-aade-0c20e7e46c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\Desktop\\ESE417_Final_Project\\WashU\\ESE_417\n",
      "Original File Path: C:\\Users\\judyw\\Desktop\\ESE417_Final_Project\\WashU\\ESE_417\\Data\\Original_Data.csv\n",
      "Data Without Outlier Path: C:\\Users\\judyw\\Desktop\\ESE417_Final_Project\\WashU\\ESE_417\\Data\\Data_Without_Outlier.csv\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4      5.0  \n",
      "1      9.8      5.0  \n",
      "2      9.8      5.0  \n",
      "3      9.8      6.0  \n",
      "4      9.4      5.0  \n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Get the path of the file\n",
    "# Current directiory for Jupyter\n",
    "script_dir = os.getcwd() \n",
    "\n",
    "# Check the path whether correct \n",
    "print(script_dir)\n",
    "\n",
    "#Buld corresponding path\n",
    "file_path = os.path.join(script_dir, \"Data\")\n",
    "Original_File_path = os.path.join(file_path, \"Original_Data.csv\")\n",
    "Data_Without_Outlier_Path = os.path.join(file_path, \"Data_Without_Outlier.csv\")\n",
    "\n",
    "# Test whether path correct\n",
    "print(\"Original File Path:\", Original_File_path)\n",
    "print(\"Data Without Outlier Path:\", Data_Without_Outlier_Path)\n",
    "\n",
    "\n",
    "# Read the csv files\n",
    "Original_Data = pd.read_csv(Original_File_path,encoding='utf-8')\n",
    "Data_Without_Outlier = pd.read_csv(Data_Without_Outlier_Path,encoding='utf-8')\n",
    "\n",
    "# Check the csv file\n",
    "print(Original_Data.head())\n",
    "print(Data_Without_Outlier.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9fe6e1-0831-4cc1-afda-6c7d0b9bf4a7",
   "metadata": {},
   "source": [
    "#### Process the the Data_Without_Outlier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7f1d00-fa60-49d4-9c79-06f951b9ada1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "The best parameter we got:  {'C': 10, 'break_ties': True, 'class_weight': 'balanced', 'decision_function_shape': 'ovr', 'gamma': 1, 'kernel': 'rbf'}\n",
      "The best parameter we got:  0.6505330882352942\n",
      "/n --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.68125\n",
      "The f1 score of the updated model is:  0.66262402551382\n",
      "The confusion_matrix of the updated model is:/n  [[  0   0   0   1   0   0]\n",
      " [  0   0   5   5   0   0]\n",
      " [  0   0  91  39   0   0]\n",
      " [  0   0  20 107   5   0]\n",
      " [  0   0   3  18  20   1]\n",
      " [  0   0   0   4   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.76      0.70      0.73       130\n",
      "           6       0.61      0.81      0.70       132\n",
      "           7       0.77      0.48      0.59        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.36      0.33      0.34       320\n",
      "weighted avg       0.67      0.68      0.66       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "outlier_x = Data_Without_Outlier.drop(['quality'], axis=1)\n",
    "outlier_y = Data_Without_Outlier['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "Outlier_x_train, Outlier_x_test, Outlier_y_train, Outlier_y_test = train_test_split(\n",
    "    outlier_x, outlier_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {Outlier_x_train.shape}\")\n",
    "print(f\"Testing data shape: {Outlier_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "Outlier_x_train_scaled = scaler.fit_transform(Outlier_x_train)\n",
    "Outlier_x_test_scaled = scaler.transform(Outlier_x_test)\n",
    "\n",
    "# Initial the parameter range\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', 'poly'],\n",
    "    'gamma': [1, 0.1, 'scale', 'auto'],\n",
    "    'class_weight': ['balanced'],                     # because the quality distributionn is un-uniform\n",
    "    'decision_function_shape': ['ovr'],               # because multi class\n",
    "    'break_ties': [True]   \n",
    "}\n",
    "# Find the best hyper parameter\n",
    "gs = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Trainning model \n",
    "gs.fit(Outlier_x_train_scaled, Outlier_y_train)\n",
    "\n",
    "# Get the best parameter depend on trainning set\n",
    "print(\"The best parameter we got: \", gs.best_params_)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best parameter we got: \", gs.best_score_)\n",
    "\n",
    "# We apply the best parameter for train model and get the data\n",
    "updated_model = SVC(**gs.best_params_)\n",
    "updated_model.fit(Outlier_x_train_scaled, Outlier_y_train)\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction = updated_model.predict(Outlier_x_test_scaled)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"/n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, final_prediction)\n",
    "f1_outlier = f1_score(Outlier_y_test, final_prediction, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, final_prediction)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_outlier)\n",
    "print(\"The confusion_matrix of the updated model is:/n \", cf_matrix)\n",
    "\n",
    "#  the classification report \n",
    "print(classification_report(Outlier_y_test, final_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e85a9-f6aa-4663-9e42-1858c18dcac2",
   "metadata": {},
   "source": [
    "#### Process the the Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4760c084-ab30-4849-9c5a-df770335135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "The best parameter we got:  {'C': 10, 'break_ties': True, 'class_weight': 'balanced', 'decision_function_shape': 'ovr', 'gamma': 1, 'kernel': 'rbf'}\n",
      "The best parameter we got:  0.6411488970588235\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.671875\n",
      "The f1 score of the updated model is:  0.6557475001636851\n",
      "The confusion_matrix of the updated model is:\n",
      " [[ 0  0  0  1  0  0]\n",
      " [ 0  0  6  4  0  0]\n",
      " [ 0  0 99 31  0  0]\n",
      " [ 0  1 31 93  7  0]\n",
      " [ 0  0  3 15 23  1]\n",
      " [ 0  0  0  4  1  0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00        10\n",
      "         5.0       0.71      0.76      0.74       130\n",
      "         6.0       0.63      0.70      0.66       132\n",
      "         7.0       0.74      0.55      0.63        42\n",
      "         8.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.35      0.34      0.34       320\n",
      "weighted avg       0.65      0.67      0.66       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "original_x = Original_Data.drop(['quality'], axis=1)\n",
    "original_y = Original_Data['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "original_x_train, original_x_test, original_y_train, original_y_test = train_test_split(\n",
    "    original_x, original_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {original_x_train.shape}\")\n",
    "print(f\"Testing data shape: {original_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "original_x_train_scaled = scaler.fit_transform(original_x_train)\n",
    "original_x_test_scaled = scaler.transform(original_x_test)\n",
    "\n",
    "# Initial the parameter range\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', 'poly'],\n",
    "    'gamma': [1, 0.1, 'scale', 'auto'],\n",
    "    'class_weight': ['balanced'],                     # because the quality distributionn is un-uniform\n",
    "    'decision_function_shape': ['ovr'],               # because multi class\n",
    "    'break_ties': [True]   \n",
    "}\n",
    "# Find the best hyper parameter\n",
    "gs = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Trainning model \n",
    "gs.fit(original_x_train_scaled, original_y_train)\n",
    "\n",
    "# Get the best parameter depend on trainning set\n",
    "print(\"The best parameter we got: \", gs.best_params_)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best parameter we got: \", gs.best_score_)\n",
    "\n",
    "# We apply the best parameter for train model and get the data\n",
    "updated_model = SVC(**gs.best_params_)\n",
    "updated_model.fit(original_x_train_scaled, original_y_train)\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction = updated_model.predict(original_x_test_scaled)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(original_y_test, final_prediction)\n",
    "f1_orig = f1_score(original_y_test, final_prediction, average='weighted') \n",
    "cf_matrix = confusion_matrix(original_y_test, final_prediction)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_orig)\n",
    "print(\"The confusion_matrix of the updated model is:\\n\", cf_matrix)\n",
    "print(\"Classification report:\\n\", classification_report(original_y_test, final_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c31a4e-2163-4480-be0d-3439b5ff1396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "Exlpained variance raitor\n",
      "HOW MANY COMPONENTS KEEPS:  7\n",
      "Find which components have been kept:\n",
      " [[ 0.50349721 -0.21946622  0.45736688  0.18873163  0.22226281 -0.06192714\n",
      "   0.01015142  0.41207779 -0.41950186  0.21187714 -0.09747018]\n",
      " [ 0.05316909 -0.39642069  0.2014572  -0.1420794  -0.30136773 -0.32592056\n",
      "  -0.44747557 -0.29671099  0.0218534   0.2406422   0.48533222]\n",
      " [-0.09817501 -0.33379644  0.18198616  0.0553366  -0.1966896   0.61884599\n",
      "   0.51866334 -0.16619321  0.02964326  0.28461977  0.20635978]\n",
      " [-0.04327114  0.20349882 -0.0522774   0.78619684  0.09014402 -0.03680007\n",
      "  -0.0654324   0.16713219  0.32061877  0.12638839  0.41882246]\n",
      " [-0.18276764  0.02665526 -0.11708226 -0.26108443  0.55357957 -0.0096233\n",
      "  -0.0917904   0.02379509  0.21890098  0.71659172 -0.08400105]\n",
      " [-0.03371095  0.14888509  0.11775918 -0.01577243  0.59449215  0.03862248\n",
      "   0.08566158 -0.46572821 -0.37528231 -0.27001498  0.41192551]\n",
      " [ 0.30657756  0.64760228 -0.18896897 -0.15188884 -0.34457988  0.09027262\n",
      "   0.03677988 -0.03010988 -0.33503492  0.36953536  0.22336832]]\n",
      "Find which components has been kept:(Index)\n",
      "  [[ 0  2  8  7  4  1  9  3 10  5  6]\n",
      " [10  6  1  5  4  7  9  2  3  0  8]\n",
      " [ 5  6  1  9 10  4  2  7  0  3  8]\n",
      " [ 3 10  8  1  7  9  4  6  2  0  5]\n",
      " [ 9  4  3  8  0  2  6 10  1  7  5]\n",
      " [ 4  7 10  8  9  1  2  6  5  0  3]\n",
      " [ 1  9  4  8  0 10  2  3  5  6  7]]\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "The best parameter we got:  {'C': 100, 'break_ties': True, 'class_weight': 'balanced', 'decision_function_shape': 'ovr', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "The best parameter we got:  0.6291796563783059\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.615625\n",
      "The f1 score of the updated model is:  0.6169564393939394\n",
      "The confusion_matrix of the updated model is:\n",
      " [[ 0  0  1  0  0  0]\n",
      " [ 0  2  3  5  0  0]\n",
      " [ 0  6 88 33  3  0]\n",
      " [ 0  4 26 84 16  2]\n",
      " [ 0  0  2 15 23  2]\n",
      " [ 0  0  0  1  4  0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.17      0.20      0.18        10\n",
      "           5       0.73      0.68      0.70       130\n",
      "           6       0.61      0.64      0.62       132\n",
      "           7       0.50      0.55      0.52        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.62       320\n",
      "   macro avg       0.33      0.34      0.34       320\n",
      "weighted avg       0.62      0.62      0.62       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "outlier_x = Data_Without_Outlier.drop(['quality'], axis=1)\n",
    "outlier_y = Data_Without_Outlier['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "Outlier_x_train, Outlier_x_test, Outlier_y_train, Outlier_y_test = train_test_split(\n",
    "    outlier_x, outlier_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {Outlier_x_train.shape}\")\n",
    "print(f\"Testing data shape: {Outlier_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "Outlier_x_train_scaled = scaler.fit_transform(Outlier_x_train)\n",
    "Outlier_x_test_scaled = scaler.transform(Outlier_x_test)\n",
    "# Do the pca process for data\n",
    "\n",
    "# Call the pca method from packages\n",
    "# Keep all components\n",
    "pca = PCA()\n",
    "pca.fit(Outlier_x_train_scaled)\n",
    "\n",
    "# Use the explained variance \n",
    "ev_result = pca.explained_variance_ratio_\n",
    "#print(\"featire {i}  ---->    ratio: {}\")\n",
    "print(\"Exlpained variance raitor\")\n",
    "\n",
    "# Get the sum of explained variance -> cumulative variance \n",
    "cv_result = pca.explained_variance_ratio_.cumsum()\n",
    "# decide how much feature contains\n",
    "threshold = 0.9\n",
    "n_features = (cv_result >= threshold).argmax() + 1\n",
    "print(\"HOW MANY COMPONENTS KEEPS: \", n_features)\n",
    "# Update new pca with limited components\n",
    "pca = PCA(n_components=n_features)\n",
    "pca.fit(Outlier_x_train_scaled)\n",
    "\n",
    "print(\"Find which components have been kept:\\n\", pca.components_)\n",
    "top_features = np.argsort(np.abs(pca.components_), axis=1)[:, ::-1]\n",
    "print(\"Find which components has been kept:(Index)\\n \", top_features)\n",
    "\n",
    "Outlier_x_train_scaled_t = pca.transform(Outlier_x_train_scaled)\n",
    "Outlier_x_test_scaled_t = pca.transform(Outlier_x_test_scaled)\n",
    "\n",
    "\n",
    "# Initial the parameter range\n",
    "# Initial the parameter range\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', 'poly'],\n",
    "    'gamma': [1, 0.1, 'scale', 'auto'],\n",
    "    'class_weight': ['balanced'],                     # because the quality distributionn is un-uniform\n",
    "    'decision_function_shape': ['ovr'],               # because multi class\n",
    "    'break_ties': [True]   \n",
    "}\n",
    "# Find the best hyper parameter\n",
    "gs = GridSearchCV(SVC(), param_grid, cv=5, scoring='f1_weighted', verbose=1)\n",
    "\n",
    "# Trainning model \n",
    "gs.fit(Outlier_x_train_scaled, Outlier_y_train)\n",
    "\n",
    "# Get the best parameter depend on trainning set\n",
    "print(\"The best parameter we got: \", gs.best_params_)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best parameter we got: \", gs.best_score_)\n",
    "\n",
    "# We apply the best parameter for train model and get the data\n",
    "updated_model = SVC(**gs.best_params_)\n",
    "updated_model.fit(Outlier_x_train_scaled_t, Outlier_y_train)\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction = updated_model.predict(Outlier_x_test_scaled_t)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, final_prediction)\n",
    "f1_pca = f1_score(Outlier_y_test, final_prediction, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, final_prediction)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_pca)\n",
    "print(\"The confusion_matrix of the updated model is:\\n\", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(Outlier_y_test, final_prediction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e43726-73ea-4746-8ac1-bc4f29c68e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56f887-e388-4074-b02f-b803d9333eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772451f-a399-46f9-8b64-c84e311b0c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.10-py310]",
   "language": "python",
   "name": "conda-env-tf2.10-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
