{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79d3eafe-f8af-4895-8da8-720f276db1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cupy as cp\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02e1e892-4b66-42f0-80d7-e9b98d7471aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\Desktop\\ESE417_Final_Project\\WashU\\ESE_417\n",
      "Original File Path: C:\\Users\\judyw\\Desktop\\ESE417_Final_Project\\WashU\\ESE_417\\Data\\Original_Data.csv\n",
      "Data Without Outlier Path: C:\\Users\\judyw\\Desktop\\ESE417_Final_Project\\WashU\\ESE_417\\Data\\Data_Without_Outlier.csv\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4      5.0  \n",
      "1      9.8      5.0  \n",
      "2      9.8      5.0  \n",
      "3      9.8      6.0  \n",
      "4      9.4      5.0  \n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Get the path of the file\n",
    "# Current directiory for Jupyter\n",
    "script_dir = os.getcwd() \n",
    "\n",
    "# Check the path whether correct \n",
    "print(script_dir)\n",
    "\n",
    "#Buld corresponding path\n",
    "file_path = os.path.join(script_dir, \"Data\")\n",
    "Original_File_path = os.path.join(file_path, \"Original_Data.csv\")\n",
    "Data_Without_Outlier_Path = os.path.join(file_path, \"Data_Without_Outlier.csv\")\n",
    "\n",
    "# Test whether path correct\n",
    "print(\"Original File Path:\", Original_File_path)\n",
    "print(\"Data Without Outlier Path:\", Data_Without_Outlier_Path)\n",
    "\n",
    "\n",
    "# Read the csv files\n",
    "Original_Data = pd.read_csv(Original_File_path,encoding='utf-8')\n",
    "Data_Without_Outlier = pd.read_csv(Data_Without_Outlier_Path,encoding='utf-8')\n",
    "\n",
    "# Check the csv file\n",
    "print(Original_Data.head())\n",
    "print(Data_Without_Outlier.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d18ee0-2db7-44aa-8a98-aa96eaf4b919",
   "metadata": {},
   "source": [
    "#### Process the the PCA Without Outlier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0035532c-9bb0-4196-b7dc-4180fcf5d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "Exlpained variance raitor\n",
      "HOW MANY COMPONENTS KEEPS:  7\n",
      "Find which components have been kept:\n",
      " [[ 0.50349721 -0.21946622  0.45736688  0.18873163  0.22226281 -0.06192714\n",
      "   0.01015142  0.41207779 -0.41950186  0.21187714 -0.09747018]\n",
      " [ 0.05316909 -0.39642069  0.2014572  -0.1420794  -0.30136773 -0.32592056\n",
      "  -0.44747557 -0.29671099  0.0218534   0.2406422   0.48533222]\n",
      " [-0.09817501 -0.33379644  0.18198616  0.0553366  -0.1966896   0.61884599\n",
      "   0.51866334 -0.16619321  0.02964326  0.28461977  0.20635978]\n",
      " [-0.04327114  0.20349882 -0.0522774   0.78619684  0.09014402 -0.03680007\n",
      "  -0.0654324   0.16713219  0.32061877  0.12638839  0.41882246]\n",
      " [-0.18276764  0.02665526 -0.11708226 -0.26108443  0.55357957 -0.0096233\n",
      "  -0.0917904   0.02379509  0.21890098  0.71659172 -0.08400105]\n",
      " [-0.03371095  0.14888509  0.11775918 -0.01577243  0.59449215  0.03862248\n",
      "   0.08566158 -0.46572821 -0.37528231 -0.27001498  0.41192551]\n",
      " [ 0.30657756  0.64760228 -0.18896897 -0.15188884 -0.34457988  0.09027262\n",
      "   0.03677988 -0.03010988 -0.33503492  0.36953536  0.22336832]]\n",
      "Find which components has been kept:(Index)\n",
      "  [[ 0  2  8  7  4  1  9  3 10  5  6]\n",
      " [10  6  1  5  4  7  9  2  3  0  8]\n",
      " [ 5  6  1  9 10  4  2  7  0  3  8]\n",
      " [ 3 10  8  1  7  9  4  6  2  0  5]\n",
      " [ 9  4  3  8  0  2  6 10  1  7  5]\n",
      " [ 4  7 10  8  9  1  2  6  5  0  3]\n",
      " [ 1  9  4  8  0 10  2  3  5  6  7]]\n",
      "The best parameters we got:  {'activation': 'relu', 'batch_size': 60, 'hidden_layer_sizes': (32, 32), 'learning_rate': 'constant', 'learning_rate_init': 0.0505, 'max_iter': 50}\n",
      "The best cross-validation score:  0.6169393382352941\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.58125\n",
      "The f1 score of the updated model is:  0.5502761824016337\n",
      "The confusion_matrix of the updated model is:\n",
      " [[ 0  0  1  0  0  0]\n",
      " [ 0  1  8  1  0  0]\n",
      " [ 2  0 93 35  0  0]\n",
      " [ 0  0 42 87  3  0]\n",
      " [ 0  0  3 34  5  0]\n",
      " [ 0  0  0  1  4  0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      0.10      0.18        10\n",
      "           5       0.63      0.72      0.67       130\n",
      "           6       0.55      0.66      0.60       132\n",
      "           7       0.42      0.12      0.19        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58       320\n",
      "   macro avg       0.43      0.27      0.27       320\n",
      "weighted avg       0.57      0.58      0.55       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "outlier_x = Data_Without_Outlier.drop(['quality'], axis=1)\n",
    "outlier_y = Data_Without_Outlier['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "Outlier_x_train, Outlier_x_test, Outlier_y_train, Outlier_y_test = train_test_split(\n",
    "    outlier_x, outlier_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {Outlier_x_train.shape}\")\n",
    "print(f\"Testing data shape: {Outlier_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "Outlier_x_train_scaled = scaler.fit_transform(Outlier_x_train)\n",
    "Outlier_x_test_scaled = scaler.transform(Outlier_x_test)\n",
    "\n",
    "# Call the pca method from packages\n",
    "# Keep all components\n",
    "pca = PCA()\n",
    "pca.fit(Outlier_x_train_scaled)\n",
    "\n",
    "# Use the explained variance \n",
    "ev_result = pca.explained_variance_ratio_\n",
    "#print(\"featire {i}  ---->    ratio: {}\")\n",
    "print(\"Exlpained variance raitor\")\n",
    "\n",
    "# Get the sum of explained variance -> cumulative variance \n",
    "cv_result = pca.explained_variance_ratio_.cumsum()\n",
    "# decide how much feature contains\n",
    "threshold = 0.9\n",
    "n_features = (cv_result >= threshold).argmax() + 1\n",
    "\n",
    "print(\"HOW MANY COMPONENTS KEEPS: \", n_features)\n",
    "# Update new pca with limited components\n",
    "pca = PCA(n_components=n_features)\n",
    "pca.fit(Outlier_x_train_scaled)\n",
    "\n",
    "print(\"Find which components have been kept:\\n\", pca.components_)\n",
    "top_features = np.argsort(np.abs(pca.components_), axis=1)[:, ::-1]\n",
    "print(\"Find which components has been kept:(Index)\\n \", top_features)\n",
    "\n",
    "Outlier_x_train_scaled_t = pca.transform(Outlier_x_train_scaled)\n",
    "Outlier_x_test_scaled_t = pca.transform(Outlier_x_test_scaled)\n",
    "\n",
    "# Define the parameters\n",
    "nodes = [16, 32, 64]\n",
    "layers = [1, 2, 3]\n",
    "hidden_layer_sizes = [\n",
    "    tuple([neuron] * layer) for neuron in nodes for layer in layers\n",
    "]\n",
    "parameter = {\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'learning_rate_init': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [50, 100, 150],  # This is epoch!\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'batch_size': [15, 30, 60]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "mlp = MLPClassifier(random_state=42,early_stopping=True, validation_fraction=0.1)\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=parameter, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(Outlier_x_train_scaled_t, Outlier_y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_mlp = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(\"The best parameters we got: \", best_params)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction_PCA = best_mlp.predict(Outlier_x_test_scaled_t)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, final_prediction_PCA)\n",
    "f1_pca = f1_score(Outlier_y_test, final_prediction_PCA, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, final_prediction_PCA)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_pca)\n",
    "print(\"The confusion_matrix of the updated model is:\\n\", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(Outlier_y_test, final_prediction_PCA))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aad4cc-45d6-426e-8480-90a24afdc206",
   "metadata": {},
   "source": [
    "#### Process the the Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c629278-2e48-4393-8c92-2a6fc292ee02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "The best parameters we got:  {'activation': 'tanh', 'batch_size': 30, 'hidden_layer_sizes': (64, 64, 64), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 50}\n",
      "The best cross-validation score:  0.6208425245098039\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.575\n",
      "The f1 score of the updated model is:  0.5466098259801261\n",
      "The confusion_matrix of the updated model is:\n",
      " [[ 0  0  1  0  0  0]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0 99 30  1  0]\n",
      " [ 0  0 48 76  8  0]\n",
      " [ 0  0  1 32  9  0]\n",
      " [ 0  0  0  1  4  0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00        10\n",
      "         5.0       0.62      0.76      0.69       130\n",
      "         6.0       0.55      0.58      0.56       132\n",
      "         7.0       0.41      0.21      0.28        42\n",
      "         8.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.57       320\n",
      "   macro avg       0.26      0.26      0.25       320\n",
      "weighted avg       0.53      0.57      0.55       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "original_x = Original_Data.drop(['quality'], axis=1)\n",
    "original_y = Original_Data['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "original_x_train, original_x_test, original_y_train, original_y_test = train_test_split(\n",
    "    original_x, original_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {original_x_train.shape}\")\n",
    "print(f\"Testing data shape: {original_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "original_x_train_scaled = scaler.fit_transform(original_x_train)\n",
    "original_x_test_scaled = scaler.transform(original_x_test)\n",
    "\n",
    "# Initial the parameter range\n",
    "parameter = {\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'learning_rate_init': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [50, 100, 150],  # This is epoch!\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'batch_size': [15, 30, 60]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "mlp_origin = MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1)\n",
    "grid_search_origin = GridSearchCV(estimator=mlp_origin, param_grid=parameter, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_origin.fit(original_x_train_scaled, original_y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_mlp_origin = grid_search_origin.best_estimator_\n",
    "best_params_origin = grid_search_origin.best_params_\n",
    "print(\"The best parameters we got: \", best_params_origin)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best cross-validation score: \", grid_search_origin.best_score_)\n",
    "\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction_original = best_mlp_origin.predict(original_x_test_scaled)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, final_prediction_original)\n",
    "f1_orig = f1_score(Outlier_y_test, final_prediction_original, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, final_prediction_original)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_orig)\n",
    "print(\"The confusion_matrix of the updated model is:\\n\", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(original_y_test, final_prediction_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "712d8ae9-b1f9-44e0-a2ed-70a01a6bf672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "The best parameters we got:  {'activation': 'tanh', 'batch_size': 15, 'hidden_layer_sizes': (16, 16), 'learning_rate': 'constant', 'learning_rate_init': 0.025750000000000002, 'max_iter': 50}\n",
      "The best cross-validation score:  0.6294393382352942\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.559375\n",
      "The f1 score of the updated model is:  0.5491751103961525\n",
      "The confusion_matrix of the updated model is:/n  [[ 0  0  1  0  0  0]\n",
      " [ 0  1  9  0  0  0]\n",
      " [ 0  3 92 35  0  0]\n",
      " [ 0  0 40 64 28  0]\n",
      " [ 0  0  0 20 22  0]\n",
      " [ 0  0  0  0  5  0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.25      0.10      0.14        10\n",
      "           5       0.65      0.71      0.68       130\n",
      "           6       0.54      0.48      0.51       132\n",
      "           7       0.40      0.52      0.45        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.56       320\n",
      "   macro avg       0.31      0.30      0.30       320\n",
      "weighted avg       0.55      0.56      0.55       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "outlier_x = Data_Without_Outlier.drop(['quality'], axis=1)\n",
    "outlier_y = Data_Without_Outlier['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "Outlier_x_train, Outlier_x_test, Outlier_y_train, Outlier_y_test = train_test_split(\n",
    "    outlier_x, outlier_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {Outlier_x_train.shape}\")\n",
    "print(f\"Testing data shape: {Outlier_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "Outlier_x_train_scaled = scaler.fit_transform(Outlier_x_train)\n",
    "Outlier_x_test_scaled = scaler.transform(Outlier_x_test)\n",
    "\n",
    "# Initial the parameter range\n",
    "parameter = {\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'learning_rate_init': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [50, 100, 150],   # This is epoch!\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'batch_size': [15, 30, 60]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "mlp = MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1)\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=parameter, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(Outlier_x_train_scaled, Outlier_y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_mlp = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(\"The best parameters we got: \", best_params)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction_outlier = best_mlp.predict(Outlier_x_test_scaled)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, final_prediction_outlier)\n",
    "f1_outlier = f1_score(Outlier_y_test, final_prediction_outlier, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, final_prediction_outlier)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_outlier)\n",
    "print(\"The confusion_matrix of the updated model is:/n \", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(Outlier_y_test, final_prediction_outlier))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da4e290-23d9-4486-bcd8-dbcb2220285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.546875\n",
      "The f1 score of the updated model is:  0.5184942455242967\n",
      "The confusion_matrix of the updated model is:/n  [[  0   0   1   0   0   0]\n",
      " [  0   0   7   3   0   0]\n",
      " [  0   0 103  27   0   0]\n",
      " [  0   0  57  61  14   0]\n",
      " [  0   0   1  30  11   0]\n",
      " [  0   0   0   2   3   0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.61      0.79      0.69       130\n",
      "           6       0.50      0.46      0.48       132\n",
      "           7       0.39      0.26      0.31        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.55       320\n",
      "   macro avg       0.25      0.25      0.25       320\n",
      "weighted avg       0.50      0.55      0.52       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initial ANN\n",
    "# Set the target and features vector for Data_Without_Outlier\n",
    "outlier_x = Data_Without_Outlier.drop(['quality'], axis=1)\n",
    "outlier_y = Data_Without_Outlier['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "Outlier_x_train, Outlier_x_test, Outlier_y_train, Outlier_y_test = train_test_split(\n",
    "    outlier_x, outlier_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {Outlier_x_train.shape}\")\n",
    "print(f\"Testing data shape: {Outlier_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "Outlier_x_train_scaled = scaler.fit_transform(Outlier_x_train)\n",
    "Outlier_x_test_scaled = scaler.transform(Outlier_x_test)\n",
    "\n",
    "# Train model\n",
    "mlp_origin.fit(Outlier_x_train_scaled, Outlier_y_train)\n",
    "initial_prediction = mlp_origin.predict(Outlier_x_test_scaled)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, initial_prediction)\n",
    "f1_outlier = f1_score(Outlier_y_test, initial_prediction, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, initial_prediction)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_outlier)\n",
    "print(\"The confusion_matrix of the updated model is:/n \", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(Outlier_y_test, initial_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1d71ada-7e35-4158-85be-37764a44bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "The best parameters we got:  {'activation': 'relu', 'batch_size': 15, 'hidden_layer_sizes': (64, 64, 64), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 50}\n",
      "The best cross-validation score:  0.6309465182704619\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.603125\n",
      "The f1 score of the updated model is:  0.5815933501384316\n",
      "The confusion_matrix of the updated model is:/n  [[ 0  0  1  0  0  0]\n",
      " [ 0  1  7  2  0  0]\n",
      " [ 0  1 89 39  1  0]\n",
      " [ 0  0 30 94  8  0]\n",
      " [ 0  1  0 32  9  0]\n",
      " [ 0  0  0  1  4  0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.33      0.10      0.15        10\n",
      "           5       0.70      0.68      0.69       130\n",
      "           6       0.56      0.71      0.63       132\n",
      "           7       0.41      0.21      0.28        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.60       320\n",
      "   macro avg       0.33      0.29      0.29       320\n",
      "weighted avg       0.58      0.60      0.58       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Set the target and features vector for Data_Without_Outlier\n",
    "outlier_x = Data_Without_Outlier.drop(['quality'], axis=1)\n",
    "outlier_y = Data_Without_Outlier['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "Outlier_x_train, Outlier_x_test, Outlier_y_train, Outlier_y_test = train_test_split(\n",
    "    outlier_x, outlier_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {Outlier_x_train.shape}\")\n",
    "print(f\"Testing data shape: {Outlier_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "Outlier_x_train_scaled = scaler.fit_transform(Outlier_x_train)\n",
    "Outlier_x_test_scaled = scaler.transform(Outlier_x_test)\n",
    "\n",
    "# Initial the parameter range\n",
    "parameter = {\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'learning_rate_init': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [50, 100, 150],   # This is epoch!\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'batch_size': [15, 30, 60]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "mlp = MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1)\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=parameter, cv=9, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(Outlier_x_train_scaled, Outlier_y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_mlp = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(\"The best parameters we got: \", best_params)\n",
    "\n",
    "# The best crossvalidation score depend on the training set\n",
    "print(\"The best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "# Predict the result based on updated model \n",
    "final_prediction_outlier = best_mlp.predict(Outlier_x_test_scaled)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(Outlier_y_test, final_prediction_outlier)\n",
    "f1_outlier = f1_score(Outlier_y_test, final_prediction_outlier, average='weighted')\n",
    "cf_matrix = confusion_matrix(Outlier_y_test, final_prediction_outlier)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_outlier)\n",
    "print(\"The confusion_matrix of the updated model is:/n \", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(Outlier_y_test, final_prediction_outlier))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0109ebd0-39ee-41f2-8c14-fa9f07c8e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1279, 11)\n",
      "Testing data shape: (320, 11)\n",
      "\n",
      " --- Evaluation under best parameters ---\n",
      "The accuracy of the updated model is:  0.409375\n",
      "The f1 score of the updated model is:  0.28686190338854645\n",
      "The confusion_matrix of the updated model is:/n  [[  0   0   0   1   0   0]\n",
      " [  0   0   5   2   3   0]\n",
      " [  0   0 119   4   7   0]\n",
      " [  0   0 120   3   9   0]\n",
      " [  0   0  32   1   9   0]\n",
      " [  0   0   3   1   1   0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00        10\n",
      "         5.0       0.43      0.92      0.58       130\n",
      "         6.0       0.25      0.02      0.04       132\n",
      "         7.0       0.31      0.21      0.25        42\n",
      "         8.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.41       320\n",
      "   macro avg       0.16      0.19      0.15       320\n",
      "weighted avg       0.32      0.41      0.29       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\judyw\\anaconda3\\envs\\tf2.10-py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initial ANN\n",
    "# Set the target and features vector for Data_Without_Outlier\n",
    "original_x = Original_Data.drop(['quality'], axis=1)\n",
    "original_y = Original_Data['quality']\n",
    "\n",
    "# Split data into training and test sets\n",
    "original_x_train, original_x_test, original_y_train, original_y_test = train_test_split(\n",
    "    original_x, original_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check training and testing data shapes\n",
    "print(f\"Training data shape: {original_x_train.shape}\")\n",
    "print(f\"Testing data shape: {original_x_test.shape}\")\n",
    "\n",
    "# Normalization data\n",
    "scaler = StandardScaler()\n",
    "original_x_train_scaled = scaler.fit_transform(original_x_train)\n",
    "original_x_test_scaled = scaler.transform(original_x_test)\n",
    "\n",
    "# Train model\n",
    "mlp_origin.fit(original_x_train_scaled, original_y_train)\n",
    "initial_prediction = mlp_origin.predict(original_x_test)\n",
    "\n",
    "# Evaluation the performance of updated model\n",
    "print(\"\\n --- Evaluation under best parameters ---\")\n",
    "accuracy = accuracy_score(original_y_test, initial_prediction)\n",
    "f1_outlier = f1_score(original_y_test, initial_prediction, average='weighted')\n",
    "cf_matrix = confusion_matrix(original_y_test, initial_prediction)\n",
    "print(\"The accuracy of the updated model is: \", accuracy)\n",
    "print(\"The f1 score of the updated model is: \", f1_outlier)\n",
    "print(\"The confusion_matrix of the updated model is:/n \", cf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report:\\n\", classification_report(original_y_test, initial_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50b372-19a0-4166-a48f-3da1c06b2f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.10-py310]",
   "language": "python",
   "name": "conda-env-tf2.10-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
